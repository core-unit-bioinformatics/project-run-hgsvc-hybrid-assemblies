{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd583875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections as col\n",
    "import re\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import pathlib as pl\n",
    "\n",
    "ts = dt.datetime.now()\n",
    "ts = ts.strftime(\"%Y%m%dT%H%M\")\n",
    "\n",
    "mount = pl.Path(\"/mounts/hilbert/project\")\n",
    "subfolder = pl.Path(\"projects/medbioinf/data/00_RESTRUCTURE\")\n",
    "data_folders = [\"nanopore\", \"pacbio_hifi\"]\n",
    "\n",
    "cell_metadata = pl.Path(\"/home/ebertp/work/code/cubi/project-run-hgsvc-hybrid-assemblies/annotations/external\")\n",
    "\n",
    "hifi_cells = cell_metadata.glob(\"*hifi*.tsv\")\n",
    "ont_cells = cell_metadata.glob(\"*ont*.tsv\")\n",
    "\n",
    "clean_out = cell_metadata.parent.joinpath(\"hgsvc_cells.tsv\")\n",
    "\n",
    "def load_cell_metadata(fpath):\n",
    "    \n",
    "    if \"jax\" in fpath.name:\n",
    "        source = \"JAX\"\n",
    "    elif \"uwash\" in fpath.name:\n",
    "        source = \"UW\"\n",
    "    elif \"umigs\" in fpath.name:\n",
    "        source = \"UMIGS\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown project {fpath.name}\")\n",
    "    if \"hifi\" in fpath.name:\n",
    "        read_type = \"HiFi\"\n",
    "    elif \"ont\" in fpath.name:\n",
    "        read_type = \"ONT\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown read type: {fpath.name}\")\n",
    "    \n",
    "    df = pd.read_csv(fpath, header=0, sep=\"\\t\")\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    df = df[[\"sample\", \"cell\"]]\n",
    "    df[\"sample\"] = df[\"sample\"].str.strip()\n",
    "    df[\"cell\"] = df[\"cell\"].str.strip()\n",
    "    df[\"sin\"] = \"SIN:\" + df[\"sample\"].str.extract(\"([0-9]+)\")\n",
    "    df[\"source\"] = source\n",
    "    df[\"read_type\"] = read_type\n",
    "    return df\n",
    "    \n",
    "hifi_cells = pd.concat(\n",
    "    [load_cell_metadata(fp) for fp in hifi_cells],\n",
    "    axis=0, ignore_index=False\n",
    ")\n",
    "hifi_exp_count = hifi_cells[\"sin\"].value_counts().to_dict()\n",
    "hifi_cells[\"exp_count\"] = hifi_cells[\"sin\"].replace(hifi_exp_count)\n",
    "\n",
    "ont_cells = pd.concat(\n",
    "    [load_cell_metadata(fp) for fp in ont_cells],\n",
    "    axis=0, ignore_index=False\n",
    ")\n",
    "ont_exp_count = ont_cells[\"sin\"].value_counts().to_dict()\n",
    "ont_cells[\"exp_count\"] = ont_cells[\"sin\"].replace(ont_exp_count)\n",
    "\n",
    "hifi_cells[\"HHU_complete\"] = \"no\"\n",
    "ont_cells[\"HHU_complete\"] = \"no\"\n",
    "hifi_cells.sort_values([\"sin\", \"cell\"], inplace=True)\n",
    "hifi_cells.reset_index(drop=True, inplace=True)\n",
    "ont_cells.sort_values([\"sin\", \"cell\"], inplace=True)\n",
    "ont_cells.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "def group_files_by_sample(fastq_files, all_known):\n",
    "    \n",
    "    sample_file_groups = col.defaultdict(list)\n",
    "    for fq in fastq_files:\n",
    "        matches = []\n",
    "        for row in all_known.itertuples():\n",
    "            if row.cell not in fq.name:\n",
    "                continue\n",
    "            matches.append((row.sample, row.cell, fq))\n",
    "        if len(matches) > 1:\n",
    "            for smp, cell, fp in matches:\n",
    "                print(smp, ' - ', cell, ' - ', fp.name)\n",
    "            raise ValueError(\"Multi-match\")\n",
    "        elif len(matches) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            sample, cell_id, file_path = matches[0]\n",
    "            sample_file_groups[sample].append(file_path)\n",
    "    return sample_file_groups\n",
    "\n",
    "\n",
    "def find_matching(sample_files, known_subset):\n",
    "    \n",
    "    missing = []\n",
    "    matched = 0\n",
    "    for cell in known_subset[\"cell\"].values:\n",
    "        is_uniq = [cell in fn for fn in sample_files]\n",
    "        is_uniq = sum(is_uniq)\n",
    "        if is_uniq == 0:\n",
    "            missing.append(cell)\n",
    "        elif is_uniq == 1:\n",
    "            matched += 1\n",
    "        else:\n",
    "            pprint_mmatch = \"\\n\".join([sf.name for sf in sample_files])\n",
    "            raise ValueError(f\"Multi-match: {is_uniq} - {cell}\", pprint_mmatch)\n",
    "\n",
    "    if matched == 0:\n",
    "        raise ValueError(\"No files matched \", sample_files, know_subset)\n",
    "    if matched != len(sample_files):\n",
    "        raise ValueError(\"Unidentified sample files \", sample_files, known_subset)\n",
    "    if missing:\n",
    "        raise ValueError(\"Missing sample files \", sample_files, known_subset)\n",
    "    sample_names = known_subset[\"sample\"].unique()\n",
    "    assert sample_names.size == 1\n",
    "    sample_name = sample_names[0]\n",
    "    if sample_name.startswith(\"GM\"):\n",
    "        sample_name = sample_name.replace(\"GM\", \"NA\")\n",
    "    return sample_name, matched\n",
    "\n",
    "\n",
    "data_types = {\n",
    "    \"nanopore\": \"ont\",\n",
    "    \"pacbio_hifi\": \"hifi\"\n",
    "}\n",
    "\n",
    "year = re.compile(\"20[0-9]{2}\")\n",
    "possible_years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "\n",
    "for data_folder in data_folders:\n",
    "    sample_folder_listings = mount.joinpath(\n",
    "        subfolder,\n",
    "        \"project-centric\",\n",
    "        \"hgsvc\",\n",
    "        data_folder\n",
    "    )\n",
    "    cell_lut = hifi_cells if data_folder == \"pacbio_hifi\" else ont_cells\n",
    "    assert sample_folder_listings.is_dir()\n",
    "    for sample_folder_lst in sample_folder_listings.glob(\"**/sample-folder.lst\"):\n",
    "        with open(sample_folder_lst, \"r\") as listing:\n",
    "            for line in listing:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                sample_folder = mount.joinpath(subfolder, line.strip())\n",
    "                mobj = year.search(line)\n",
    "                if mobj is None:\n",
    "                    raise ValueError(\"no year \", line.strip())\n",
    "                else:\n",
    "                    ds_year = mobj.group(0)\n",
    "                    assert ds_year in possible_years\n",
    "                sample_num = \"SIN:\" + sample_folder.name[2:]\n",
    "                if sample_num not in cell_lut[\"sin\"].values:\n",
    "                    unsorted_fastq = list(sample_folder.glob(\"**/*.fastq.gz\"))\n",
    "                    if not unsorted_fastq:\n",
    "                        raise ValueError(sample_folder)\n",
    "                    sample_file_groups = group_files_by_sample(\n",
    "                        unsorted_fastq,\n",
    "                        cell_lut\n",
    "                    )\n",
    "                    for sample, sample_files in sample_file_groups.items():\n",
    "                        sample_num = \"SIN:\" + sample[2:]\n",
    "                        fastq_names = [sf.name for sf in sample_files]\n",
    "                        subset = cell_lut.loc[cell_lut[\"sin\"] == sample_num, :]\n",
    "                        if subset.shape[0] != len(fastq_names):\n",
    "                            print(\"Missing files \", line.strip(), subset.shape[0], len(fastq_names))\n",
    "                            continue\n",
    "                        sample_name, matched_files = find_matching(fastq_names, subset)\n",
    "                        # not raising = dataset complete\n",
    "                        check_file = sample_folder.joinpath(\n",
    "                            f\"{sample_name}.{matched_files}-cells.verified\"\n",
    "                        )\n",
    "                        #if not check_file.is_file():\n",
    "                        if True:\n",
    "                            with open(check_file, \"w\") as dump:\n",
    "                                dump.write(f\"# {ts}\\n\")\n",
    "                                subset.to_csv(dump, sep=\"\\t\", header=True, index=False)\n",
    "                            relpaths_fastq = sorted(\n",
    "                                [f.relative_to(mount.joinpath(subfolder)) for f in sample_files]\n",
    "                            )\n",
    "                            relpaths_fastq = list(map(str, relpaths_fastq))\n",
    "                            fofn_path = mount.joinpath(\n",
    "                                subfolder, \"sample-centric\", sample_name,\n",
    "                                f\"{sample_name}_{data_types[data_folder]}_fastq.hgsvc-{ds_year}.fofn\"\n",
    "                            )\n",
    "                            fofn_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "                            with open(fofn_path, \"w\") as fofn:\n",
    "                                fofn.write(\"\\n\".join(relpaths_fastq) + \"\\n\")\n",
    "                        cell_lut.loc[subset.index, \"HHU_complete\"] = \"yes\"\n",
    "                        \n",
    "                else:\n",
    "                    # easy case: data per sample in subfolder\n",
    "                    fastq = list(sample_folder.glob(\"**/*.fastq.gz\"))\n",
    "                    if not fastq:\n",
    "                        raise ValueError(sample_folder)\n",
    "                    fastq_names = [fp.name for fp in fastq]\n",
    "                    subset = cell_lut.loc[cell_lut[\"sin\"] == sample_num, :]\n",
    "                    if subset.shape[0] != len(fastq):\n",
    "                        #print(\"Missing files \", line.strip(), subset.shape[0], len(fastq))\n",
    "                        #print(\"Skipping\")\n",
    "                        continue\n",
    "                    sample_name, matched_files = find_matching(fastq_names, subset)\n",
    "                    # not raising = dataset complete\n",
    "                    check_file = sample_folder.joinpath(\n",
    "                        f\"{sample_name}.{matched_files}-cells.verified\"\n",
    "                    )\n",
    "                    if not check_file.is_file():\n",
    "                        with open(check_file, \"w\") as dump:\n",
    "                            dump.write(f\"# {ts}\\n\")\n",
    "                            subset.to_csv(dump, sep=\"\\t\", header=True, index=False)\n",
    "                        relpaths_fastq = sorted([f.relative_to(mount.joinpath(subfolder)) for f in fastq])\n",
    "                        relpaths_fastq = list(map(str, relpaths_fastq))\n",
    "                        fofn_path = mount.joinpath(\n",
    "                            subfolder, \"sample-centric\", sample_name,\n",
    "                            f\"{sample_name}_{data_types[data_folder]}_fastq.hgsvc-{ds_year}.fofn\"\n",
    "                        )\n",
    "                        fofn_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "                        with open(fofn_path, \"w\") as fofn:\n",
    "                            fofn.write(\"\\n\".join(relpaths_fastq) + \"\\n\")\n",
    "                    cell_lut.loc[subset.index, \"HHU_complete\"] = \"yes\"\n",
    "                \n",
    "merged = pd.concat([hifi_cells, ont_cells], axis=0, ignore_index=False)\n",
    "merged.sort_values([\"sin\", \"read_type\", \"source\", \"cell\"], inplace=True)\n",
    "merged.to_csv(clean_out, header=True, index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
